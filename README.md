# ğŸ› ï¸ Corrective RAG  
A fully modular **Corrective Retrieval-Augmented Generation (RAG)** pipeline built using **LangGraph**, **Streamlit**, and **Groq LLMs**.

This project demonstrates an advanced RAG system that **retrieves, grades, refines, and augments context** before generating an answer â€” significantly improving reliability compared to standard single-pass RAG.

---

## ğŸ§© How It Works

The **Corrective RAG pipeline** follows these intelligent steps:

### **1ï¸âƒ£ Retrieve**  
Fetch candidate documents from the local knowledge base.

### **2ï¸âƒ£ Grade**  
Evaluate each retrieved document to determine how relevant it is to the userâ€™s query.

### **3ï¸âƒ£ Transform**  
If the retrieval quality is poor, automatically **rewrite** the user query using an LLM to get better retrieval results.

### **4ï¸âƒ£ Web Search (Fallback)**  
If domain knowledge is missing, trigger an **external search** (e.g., Tavily API) to bring in fresh information.

### **5ï¸âƒ£ Generate**  
Use **Groq-hosted LLMs** to produce the final answer using the best available context.

### **6ï¸âƒ£ UI Feedback**  
The **Streamlit frontend** displays each workflow step:
- Retrieved docs  
- Relevance grades  
- Rewritten queries  
- Web search results  
- Final generated answer  

This provides complete **transparency of the reasoning pipeline**.

---

## ğŸš€ Features

- ğŸ“„ **Document Retrieval & Grading**  
  Retrieves documents and filters them based on relevance.

- ğŸ”„ **Automatic Query Transformation**  
  Rewrites user questions when retrieval is weak.

- ğŸŒ **Web Search Fallback**  
  Adds missing or new knowledge when necessary.

- ğŸ¤– **LLM-Powered Answer Generation**  
  Uses Groq-hosted LLMs for fast, low-latency inference.

- ğŸ“Š **Execution Logs in UI**  
  Transparent end-to-end visualization of:  
  `retrieve â†’ grade â†’ transform â†’ search â†’ generate`

---

## ğŸ“‚ Project Structure
```bash
CorrectiveRAG/
â”‚
â”œâ”€â”€ app.py # Streamlit app (UI entrypoint)
â”œâ”€â”€ main.py # CLI runner for workflow debugging
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ README.md # Documentation
â”œâ”€â”€ .env.example # Environment variable template
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ langgraphCorrectiveAI/
â”‚ â”‚ â”œâ”€â”€ graph/
â”‚ â”‚ â”‚ â””â”€â”€ workflow.py # Core workflow graph
â”‚ â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ nodes/ # Workflow nodes
â”‚ â”‚ â”‚ â”œâ”€â”€ retrieve_node.py
â”‚ â”‚ â”‚ â”œâ”€â”€ grade_node.py
â”‚ â”‚ â”‚ â”œâ”€â”€ transform_node.py
â”‚ â”‚ â”‚ â”œâ”€â”€ web_search_node.py
â”‚ â”‚ â”‚ â””â”€â”€ generate_node.py
â”‚ â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ tools/
â”‚ â”‚ â”‚ â””â”€â”€ search_tool.py # Embeddings, retrieval, search utilities
â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€ state/
â”‚ â”‚ â””â”€â”€ graph_state.py # Shared workflow state
â”‚ â”‚
â”‚ â””â”€â”€ UI/streamlitUI/
â”‚ â”œâ”€â”€ display_result.py
â”‚ â”œâ”€â”€ loadui.py
â”‚ â””â”€â”€ uiconfigfile.py
```

## âš™ï¸ Installation & Setup

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/daanyal-23/corrective-rag-demo.git
cd corrective-rag-demo
```
2ï¸âƒ£ Create a Virtual Environment
```bash
Copy code
python -m venv venv
Windows
```
```bash
Copy code
venv\Scripts\activate
Mac/Linux
```
```bash
Copy code
source venv/bin/activate
```
3ï¸âƒ£ Install Dependencies
```bash
Copy code
pip install -r requirements.txt
```
4ï¸âƒ£ Configure Environment Variables
Create a .env file in the project root:

Copy code
GROQ_API_KEY=your_groq_api_key
TAVILY_API_KEY=your_tavily_api_key
(You may also include any embedding model keys if needed.)

5ï¸âƒ£ Run the Streamlit App
```bash
streamlit run app.py
```
ğŸ§ª Example Workflow
Enter a question in the Streamlit interface.

System retrieves documents and grades relevance.

If retrieval is poor, query is rewritten for improvement.

If required, external web search is triggered.

Groq LLM generates the final, grounded answer.

UI shows each step with explanations.

ğŸ“Œ Future Improvements
âœ… Add unit tests for workflow nodes

âœ… Enhance frontend visualization

âœ… Add multi-vector-store support (FAISS, Pinecone, Chroma)

âœ… Dockerize for easier deployment

â³ Add evaluator agent for grounding verification

â³ Add streaming output support in UI

ğŸ¤ Contributing
Contributions are welcome!
Please open an issue before submitting major changes so we can discuss your ideas.

â¤ï¸ Built With
LangGraph â€“ workflow orchestration

Groq LLMs â€“ fast inference

Streamlit â€“ interactive frontend

Python â€“ glue for all components
